<!DOCTYPE html>
<html lang="en" id="top">

<head>

  <!-- Basic Page Needs
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->

  <meta charset="utf-8">
  <title>Miguel Méndez | Automatic Classification of an online Fashion Catalogue</title>
  <meta name="author" content="Miguel Mendez">
  <meta property="og:website" content="Miguel Mendez personal website">
  <meta name="robots" content="max-image-preview:large">
  
  
  <meta name="description" property="og:description" content="Learn to find a public fashion dataset, download it and process it for training a classification model on Tensorflow">
  

  
  <meta name="image" property="og:image" content="https://miguel-mendez-ai.com/assets/images/fullsize/posts/2019-06-07-fashion/thumbnail.jpg">
  

  <!-- Mobile Specific Metas
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <!-- CSS
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->

  <!-- preload fonts -->
  <link rel="preload" href="/libs/external/fonts/Graphik-Regular.woff2"" as="font" type="font/woff2" crossorigin>
  <link rel="preload" href="/libs/external/fonts/Graphik-Semibold.woff2"" as="font" type="font/woff2" crossorigin>
  <link rel="preload" href="/libs/external/fonts/Tiempos-Headline-Semibold.woff2"" as="font" type="font/woff2" crossorigin>

  <link rel="stylesheet" href=/libs/custom/my_css.css>
  <link rel="stylesheet" href=/libs/external/fonts/fonts.css>

  <!-- hack for non critical css https://web.dev/defer-non-critical-css/ -->
  <link rel="preload" href=/libs/custom/syntax.css as="style" onload="this.onload=null;this.rel='stylesheet'">
  <noscript><link rel="stylesheet" href=/libs/custom/syntax.css></noscript>
  
  <!-- non critical lighthouse css -->
  <link rel="preload" href=/libs/external/lightbox/lightbox.css as="style" onload="this.onload=null;this.rel='stylesheet'">
  <noscript><link rel="stylesheet" href=/libs/external/lightbox/lightbox.css></noscript>

  <!-- Fontello
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <link rel="stylesheet"
    href=/libs/external/fontello-bb2d1770/css/fontello.css>

  <!-- Favicon
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <link rel="icon" type="image/png" href=/libs/icon.png>
  <link rel="shortcut icon" type="image/png" href=/libs/icon.png>

  <!-- Google Analytics -->
  <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-LMHYVFNF1J"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-LMHYVFNF1J');
</script>
    <!-- Twitter cards -->
  <meta name="twitter:site" content="@https://twitter.com/mmeendez8">
  <meta name="twitter:title" content="Automatic Classification of an online Fashion Catalogue">
  
  
  <meta name="twitter:description" content="Learn to find a public fashion dataset, download it and process it for training a classification model on Tensorflow">
  
  

  
  <meta name="twitter:card"  content="summary_large_image">
  <meta name="twitter:image" content="https://miguel-mendez-ai.com/assets/images/fullsize/posts/2019-06-07-fashion/thumbnail.jpg">
  

  <!-- end of Twitter cards -->
  

</head>

<body>

  <header class="the-post-header">
    <div class="container">
      <a href="/">
        <h3>Miguel Méndez</h3>
      </a>
      <div>
        <a  href=/index.html#posts>
         <h3 class="posts-link">Posts</h3>
        </a>
      </div>
    </div>
</header>

<div class="the-post-title-placeholder">
  <div class="offset">
    <div class="the-post-title-text">
      <span class="the-post-date">June 07, 2019 </span>
      <h1 class="the-post-title">Automatic Classification of an online Fashion Catalogue</h1>
      <p>Scrap data and train a model</p>
    </div>
  </div>

  <div class="the-post-title-image">
    <img src="/generated/assets/images/fullsize/posts/2019-06-07-fashion/thumbnail-800-f6473f507.jpg" alt="Automatic Classification of an online Fashion Catalogue" srcset="/generated/assets/images/fullsize/posts/2019-06-07-fashion/thumbnail-400-2952f5f5f.webp 400w, /generated/assets/images/fullsize/posts/2019-06-07-fashion/thumbnail-600-2952f5f5f.webp 600w, /generated/assets/images/fullsize/posts/2019-06-07-fashion/thumbnail-800-2952f5f5f.webp 800w, /generated/assets/images/fullsize/posts/2019-06-07-fashion/thumbnail-1200-2952f5f5f.webp 1200w" sizes="(max-width: 767px) 100vw, 50vw" width="1200" height="675">

  </div>
</div>

<div class="share-button">
  <a href="https://twitter.com/share?ref_src=twsrc%5Etfw" class="twitter-share-button" data-show-count="false" ,
    data-size="large" , data-text="Automatic Classification of an online Fashion Catalogue" , data-via="mmeendez8" , data-url="https://miguel-mendez-ai.com/2019/06/07/fashion.html">
  </a>
</div>

<div class="container the-post-content">

  <p>I have been working with Tensorflow during last months and I realized that, although there is a large number of Github repositories with many different and complex models, is hard to find a simple example that shows you how to obtain your own dataset from the web and apply some Deep Learning on it.</p>

<p>In this post I pretended to provide an example of this task but being keeping it as simple as possible. I will show you how to <strong>obtain online unlabeled data</strong>, how to create a <strong>simple convolutional network</strong>, train it with some supervised data and use it later to <strong>classify the data</strong> we have gathered from the web.
You can also find this post in <a href="https://towardsdatascience.com/automatic-classification-of-an-online-fashion-catalogue-the-simple-way-2a4b13a2af0a" target="_blank" rel="noopener noreferrer">Medium</a></p>

<p>All code can be found on my <a href="https://github.com/mmeendez8/garment-classifier" target="_blank" rel="noopener noreferrer">Github account</a></p>

<h2 id="1-data-scraping">1. Data Scraping</h2>

<p>If you are close to Data Science world you probably have heard about the <a href="https://github.com/zalandoresearch/fashion-mnist" target="_blank" rel="noopener noreferrer">Fashion MNIST dataset</a>. It’s a super simple collection of 28x28 images consisting of a training set of 60,000 examples and a test set of 10,000 examples. The data is associated with a label from 10 classes as Trouser, Pullover, Dress, Coat…</p>

<div class="post-center-image">
<a href="/assets/images/fullsize/posts/2019-06-07-fashion/fashion_mnist.jpg">
  <img loading="lazy" src="/generated/assets/images/fullsize/posts/2019-06-07-fashion/fashion_mnist-564-8de69bf15.jpg" alt="Fashion mnist capture" srcset="/generated/assets/images/fullsize/posts/2019-06-07-fashion/fashion_mnist-400-e8e2e3b4c.webp 400w, /generated/assets/images/fullsize/posts/2019-06-07-fashion/fashion_mnist-564-e8e2e3b4c.webp 564w" sizes="(max-width: 767px) 100vw, 80vw" width="564" height="325" />
</a>

</div>

<p>So the idea is simple, we train our network with the MNIST data and we use then to classify the data obtained from the actual Zalando’s catalogue.</p>

<p>Data scraping is a very important task if you are a Data Scientist. Most of the time you will not have available the data you are looking for, so you will need to obtain it from the web. The procedure is pretty simple if you know a little bit of HTML and CSS.</p>

<h2 id="2-neural-network">2. Neural Network</h2>

<p>We are going to classify small grey scaled images so we will not need a super complex architecture. I basically stacked two convolutional layers with their correspondent pooling layer (<a href="https://mirror2image.wordpress.com/2014/11/11/geoffrey-hinton-on-max-pooling-reddit-ama/" target="_blank" rel="noopener noreferrer">check what Hinton thinks about Pool Layers</a>). After this a dense layer followed by a dropout operation and a final dense layer with a softmax function. Classic and simple stuff!</p>

<script src="https://gist.github.com/mmeendez8/8b2589a1cf0d336fba2de804ee8a57a2.js"></script>

<p>If you have problems understanding what that decorator is doing you can check my previous post: <a href="https://towardsdatascience.com/generating-fake-fifa-19-football-players-with-variational-autoencoders-and-tensorflow-aff6c10016ae" target="_blank" rel="noopener noreferrer">Generating fake FIFA 19 football players with Variational Autoencoders and Tensorflow</a> or <a href="https://danijar.com/structuring-your-tensorflow-models/" target="_blank" rel="noopener noreferrer">this amazing post</a> from <a href="https://danijar.com/" target="_blank" rel="noopener noreferrer">Danijar Hafner</a>.</p>

<h2 id="3-training-the-network">3. Training the network</h2>

<p>For the training task I have used Adam Optimizer and let algorithm run for just 100 epochs. You can apply longer and better training to improve the accuracy as much as you want and I would also recommend you to change the network structure adding some extra layers.</p>

<p>The training file allows you to observe how you accuracy and loss evolve with the number of epochs. These were my results:</p>

<div class="post-center-image">
<a href="/assets/images/fullsize/posts/2019-06-07-fashion/acc.jpg">
  <img loading="lazy" src="/generated/assets/images/fullsize/posts/2019-06-07-fashion/acc-396-3b78c03ee.jpg" alt="Accuracy results" srcset="/generated/assets/images/fullsize/posts/2019-06-07-fashion/acc-396-555dff99e.webp 396w" sizes="(max-width: 767px) 100vw, 80vw" width="396" height="275" />
</a>

</div>

<div class="post-center-image">
<a href="/assets/images/fullsize/posts/2019-06-07-fashion/loss.jpg">
  <img loading="lazy" src="/generated/assets/images/fullsize/posts/2019-06-07-fashion/loss-415-12a6f5889.jpg" alt="Loss results" srcset="/generated/assets/images/fullsize/posts/2019-06-07-fashion/loss-400-5b38321f5.webp 400w, /generated/assets/images/fullsize/posts/2019-06-07-fashion/loss-415-5b38321f5.webp 415w" sizes="(max-width: 767px) 100vw, 80vw" width="415" height="288" />
</a>

</div>

<p>Remember that when we train our model we must validate our data with a different dataset to avoid overfitting issues (between others). In this case we can use Fashion MNIST test set!</p>

<h2 id="4-evaluate-results">4. Evaluate results</h2>

<p>Once the network has been trained and saved, we can proceed to evaluate its performance with the scraped dataset. Look at this code snippet:</p>

<script src="https://gist.github.com/mmeendez8/60f0d75a0c6a7d3ae2b26a93bcef92ec.js"></script>

<p>It’s pretty simple. What I do in here is recovering the network and loading the unlabeled data. I recover two important tensors which are the ones that I use to feed new data and to output the predictions of the network. Finally I pass 5 different images to the network and this is what I get:</p>

<div class="post-center-image">
<a href="/assets/images/fullsize/posts/2019-06-07-fashion/result.jpg">
  <img loading="lazy" src="/generated/assets/images/fullsize/posts/2019-06-07-fashion/result-800-111d90bc1.jpg" alt="Image results" srcset="/generated/assets/images/fullsize/posts/2019-06-07-fashion/result-400-0f6fa0d6e.webp 400w, /generated/assets/images/fullsize/posts/2019-06-07-fashion/result-600-0f6fa0d6e.webp 600w, /generated/assets/images/fullsize/posts/2019-06-07-fashion/result-800-0f6fa0d6e.webp 800w, /generated/assets/images/fullsize/posts/2019-06-07-fashion/result-1500-0f6fa0d6e.webp 1500w" sizes="(max-width: 767px) 100vw, 80vw" width="1727" height="409" />
</a>

</div>

<p>Note that I did not show the whole process here, since the images we obtained from the web must be converted to 28x28 gray scale images before being inserted to the network, once more I encourage you to check the whole code on <a href="https://github.com/mmeendez8/garment-classifier" target="_blank" rel="noopener noreferrer">Github</a>.</p>

<p>Well, that’s all we need to classify the unlabeled images we obtain from Zalando’s website. You could use this to create a labeled dataset of images to train another different model or anything that you can think on!</p>

<p><em>Any ideas for future posts or is there something you would like to comment? Please feel free to reach out via <a href="https://twitter.com/mmeendez8" target="_blank" rel="noopener noreferrer">Twitter</a> or <a href="https://github.com/mmeendez8" target="_blank" rel="noopener noreferrer">Github</a></em></p>

  
</div>

<div class="comments">
  <script src="https://utteranc.es/client.js"
        repo="mmeendez8/mmeendez8.github.io"
        issue-term="url"
        theme="github-light"
        crossorigin="anonymous"
        async>
  </script>
</div>

    <div class="footer">
      <div class="footer-sign">
      <p> <a  href=/index.html#top>Miguel Méndez </a></p>
      </div>

      <div class="footer-thanks">
        <p>based on <a href="http://web.media.mit.edu/~msaveski" target="_blank" rel="noopener">Martin Saveski</a> and <a href='https://marinaaisa.com/' target="_blank" rel="noopener">Marina Aisa</a> templates</p>
      </div>

      <div class="footer-icons">
        <a href='https://github.com/mmeendez8' target="_blank" rel="noopener">
          <i class="icon-github-circled" aria-hidden="true"></i>
        </a>

        <a href='https://www.linkedin.com/in/miguel-mendez/' target="_blank" rel="noopener">
          <i class="icon-linkedin-squared" aria-hidden="true"></i>
        </a>

        <a href='https://twitter.com/mmeendez8' target="_blank" rel="noopener">
          <i class="icon-twitter-squared" aria-hidden="true"></i>
        </a>

        <a href='https://medium.com/@miguelmendez_' target="_blank" rel="noopener">
          <i class="icon-medium" aria-hidden="true"></i>
        </a>

        <a href='https://stackoverflow.com/users/8380638/m33n' target="_blank" rel="noopener">
          <i class="icon-stackoverflow" aria-hidden="true"></i>
        </a>

        <a href='/feed.xml' target="_blank" rel="noopener">
          <i class="icon-rss-squared" aria-hidden="true"></i>
        </a>
        
      </div>

    </div>

  <!-- End Document
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <script type="text/javascript" src=/libs/external/lightbox/lightbox.js defer></script>
  
  <!-- Mathjax -->
  

</body>

</html>
