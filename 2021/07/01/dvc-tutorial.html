<!DOCTYPE html>
<html lang="en" id="top">

<head>

  <!-- Basic Page Needs
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->

  <meta charset="utf-8">

  <title>Version control your dataset with DVC</title>

  <meta name="author" content="Miguel Mendez">
  <meta property="og:website" content="Miguel Mendez personal website">
  <meta name="robots" content="max-image-preview:large">
  <meta name="title" property="og:title" content="Version control your dataset with DVC">

  
  <meta name="description" property="og:description" content="Learn how to use DVC with a Google Drive remote for tracking changes on your dataset and create Continuous Integration pipelines at Github to test your data as you do with code.">
  

  
  <meta name="image" property="og:image" content="https://miguel-mendez-ai.com/assets/images/fullsize/posts/2021-07-01-dvc-tutorial/thumbnail.jpg">
  

  <meta property="og:url" content="https://miguel-mendez-ai.com/2021/07/01/dvc-tutorial">

  <!-- Set canonical link to avoid duplication in google search -->
  <link rel="canonical" href="https://miguel-mendez-ai.com/2021/07/01/dvc-tutorial">

  <!-- Mobile Specific Metas
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <!-- CSS
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->

  <!-- preload fonts -->
  <link rel="preload" href="/libs/external/fonts/Graphik-Regular.woff2" as="font" type="font/woff2" crossorigin>
  <link rel="preload" href="/libs/external/fonts/Graphik-Semibold.woff2" as="font" type="font/woff2" crossorigin>
  <link rel="preload" href="/libs/external/fonts/Tiempos-Headline-Semibold.woff2" as="font" type="font/woff2" crossorigin>

  <link rel="stylesheet" href=/libs/custom/my_css.css>
  <link rel="stylesheet" href=/libs/external/fonts/fonts.css>

  <!-- hack for non critical css https://web.dev/defer-non-critical-css/ -->
  <link rel="preload" href=/libs/custom/syntax.css as="style" onload="this.onload=null;this.rel='stylesheet'">
  <noscript><link rel="stylesheet" href=/libs/custom/syntax.css></noscript>
  
  <!-- non critical lighthouse css -->
  <link rel="preload" href=/libs/external/lightbox/lightbox.css as="style" onload="this.onload=null;this.rel='stylesheet'">
  <noscript><link rel="stylesheet" href=/libs/external/lightbox/lightbox.css></noscript>

  <!-- Fontello
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <link rel="stylesheet"
    href=/libs/external/fontello-bb2d1770/css/fontello.css>


  <!-- Hihglight.js
  <!-- Preload CSS -->
  <link rel="preload" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/atom-one-dark.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <noscript><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/default.min.css"></noscript>
  
  <!-- Load only necessary languages (example: javascript and python) -->
  <script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
  <script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/languages/javascript.min.js"></script>
  <script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/languages/python.min.js"></script>
  <script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/languages/bash.min.js"></script>
  <script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/languages/yaml.min.js"></script>
  <script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/languages/dockerfile.min.js"></script>


  <!-- Favicon
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <link rel="icon" type="image/png" href=/libs/icon.png>
  <link rel="shortcut icon" type="image/png" href=/libs/icon.png>

  <!-- RSS Feed -->
  <link rel="alternate" type="application/atom+xml" href="https://miguel-mendez-ai.com/feed.xml">


  <!-- Google Analytics -->
  <!-- Global site tag (gtag.js) - Google Analytics -->
<!-- <script async src="https://www.googletagmanager.com/gtag/js?id=G-LMHYVFNF1J"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-LMHYVFNF1J');
</script> -->
    <!-- Twitter cards -->
  <meta name="twitter:site" content="@https://twitter.com/mmeendez8">
  <meta name="twitter:title" content="Version control your dataset with DVC">
  
  
  <meta name="twitter:description" content="Learn how to use DVC with a Google Drive remote for tracking changes on your dataset and create Continuous Integration pipelines at Github to test your data as you do with code.">
  
  

  
  <meta name="twitter:card"  content="summary_large_image">
  <meta name="twitter:image" content="https://miguel-mendez-ai.com/assets/images/fullsize/posts/2021-07-01-dvc-tutorial/thumbnail.jpg">
  

  <!-- end of Twitter cards -->
  

</head>

<body>

  <!-- schema.org markup to help SEO -->
<script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "BlogPosting",
    "headline": "Version control your dataset with DVC",
    "datePublished": "2021-07-01T00:00:00+00:00",
    "dateModified": "2021-07-01T00:00:00+00:00",
    "author": {
      "@type": "Person",
      "name": "Miguel Mendez",
      "url": "https://miguel-mendez-ai.com"
    },
    "description": "Learn how to use DVC with a Google Drive remote for tracking changes on your dataset and create Continuous Integration pipelines at Github to test your data as you do with code.",
    "image": "https://miguel-mendez-ai.com/assets/images/fullsize/posts/2021-07-01-dvc-tutorial/thumbnail.jpg",
    "keywords": "DVC, Data Version Control, Machine Learning, Git, CI/CD",
    "articleSection": "Machine Learning, Data Engineering"
  }
  </script>

<header class="the-post-header">
    <div class="container">
      <a href="/">
        <h3>Miguel Méndez</h3>
      </a>
      <div>
        <a  href=/index.html#posts>
         <h3 class="posts-link">Posts</h3>
        </a>
      </div>
    </div>
</header>

<div class="the-post-title-placeholder">
  <div class="offset">
    <div class="the-post-title-text">
      <span class="the-post-date">July 01, 2021 </span>
      <h1 class="the-post-title">Version control your dataset with DVC</h1>
      <p>Use DVC and Git for tracking changes on your machine learning dataset</p>
    </div>
  </div>

  <div class="the-post-title-image">
    <img fetchpriority="high" src="/generated/assets/images/fullsize/posts/2021-07-01-dvc-tutorial/thumbnail-800-601183df4.jpg" alt="Version control your dataset with DVC" srcset="/generated/assets/images/fullsize/posts/2021-07-01-dvc-tutorial/thumbnail-1200-cd6ecdf64.webp 1200w" sizes="(max-width: 767px) 100vw, 50vw" width="1200" height="627">

  </div>
</div>

<div class="container the-post-content">

  <p><a href="https://dvc.org/" target="_blank" rel="noopener noreferrer">Data Version Control (DVC)</a> is one of the most amazing projects in recent years. Before using it, we used to have trouble reproducing our models and experiments. We store our images and annotations in high-volume network attached storage where multiple people work every day, so there was no proper way to modify images or annotations while maintaining a correct and reproducible change history. You can imagine how often someone accidentally deletes an image, modifies some annotations, or infinitely more random problems that ended in trouble for properly reproducing our experiments.</p>

<p>In this post I will try to show how to configure DVC and how it can help us to maintain version of our datasets that can be easily integrated with Github.</p>

<h2 id="why-dvc">Why DVC?</h2>

<p>The first thing we should do is understanding how DVC works, we can check its <a href="https://dvc.org/" target="_blank" rel="noopener noreferrer">landing page</a> which contains some intuitive explanations:</p>

<ul>
  <li>Machine Learning projects are defined by code and data</li>
  <li>We know how to track code using git</li>
  <li>DVC main target is to built something similar to git for tracking data and models. It must be:
    <ul>
      <li>Flexible</li>
      <li>Easy to learn</li>
      <li>Work with any ML framework</li>
    </ul>
  </li>
</ul>

<p>I always recommend to watch this introduction video that greatly summarizes the main idea behind this tool.</p>

<center>
    <iframe loading="lazy" width="560" height="315" src="https://www.youtube.com/embed/UbL7VUpv1Bs" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
    </iframe>
</center>

<p>If you paid attention, you will probably have a general idea of how this large files are tracked. Light-weight files (.dvc files) are used as “pointers” to large files, so we can use git to track those pointers and then retrieve the associated large files in our local filesystem with dvc. In other words, you do not need to worry anymore about uploading large files to git (forget about LFS), DVC will handle everything for you once it is properly configured. That’s pretty cool isn’t it?</p>

<h2 id="setting-up-the-environment">Setting up the environment</h2>

<p>I have pushed all changes to a <a href="https://github.com/mmeendez8/coco_sample/" target="_blank" rel="noopener noreferrer">Github repository</a> that you can consult in case you need.</p>

<h3 id="install-dvc">Install DVC</h3>

<p>Let’s setup DVC for our experiment. If you check their <a href="https://dvc.org/doc/install/linux#installation-on-linux" target="_blank" rel="noopener noreferrer">installation guide</a>, you will realize that depending on the type of remote storage you plan to use, it might be necessary to install additional deps. For this tutorial we are going to use Google Drive because it is probably the most accesible to everyone. I always use Conda environment for Python package management, do the following for creating a new environment and installing dvc on it:</p>

<pre><code class="language-bash">conda  create -n coco_sample python=3.8 -y
conda activate coco_sample
pip install dvc[gdrive]
</code></pre>

<h3 id="get-the-data">Get the data</h3>

<p>We are going to use a <a href="https://course.fast.ai/datasets#coco" target="_blank" rel="noopener noreferrer">subset of the COCO dataset created by fast.ai</a>. The fast.ai subset contains all images that contain one of five selected categories, restricting objects to just those five categories; the categories are: chair couch tv remote book vase. You can download and extract it using the following commands:</p>

<pre><code class="language-bash">wget https://s3.amazonaws.com/fast-ai-coco/coco_sample.tgz -P data
tar zxvf data/coco_sample.tgz -C data
rm  data/coco_sample.tgz
</code></pre>

<p>You should now have all images in <code>data/coco_sample/train_sample</code> and their corresponding annotations in <code>data/coco_sample/annotations/train_sample.json</code></p>

<h3 id="visualize-our-data">Visualize our data</h3>

<p>It is always good to take a look at the data to get an idea of what kind of images we are dealing with. We are going to use our tool <a href="https://github.com/Gradiant/pyodi" target="_blank" rel="noopener noreferrer">pyodi</a>, which allows us to retrieve annotations from a COCO formatted file and paint then over the corresponding image. We can install it using pip and run the paint-annotations script pointing to our data and annotations folder:</p>

<pre><code class="language-bash">pip install pyodi
pyodi paint-annotations data/coco_sample/annotations/train_sample.json data/coco_sample/train_sample output/painted_images --first_n 10
</code></pre>

<p>This will paint the first 10 images of the dataset and save them into <code>output/painted_images</code> folder.</p>

<div class="post-center-image">
<a href="/assets/images/fullsize/posts/2021-07-01-dvc-tutorial/painted_coco_sample.jpg">
  <img loading="lazy" src="/generated/assets/images/fullsize/posts/2021-07-01-dvc-tutorial/painted_coco_sample-666-8250e9564.jpg" alt="Coco image with painted detections" srcset="/generated/assets/images/fullsize/posts/2021-07-01-dvc-tutorial/painted_coco_sample-400-6775c1de5.webp 400w, /generated/assets/images/fullsize/posts/2021-07-01-dvc-tutorial/painted_coco_sample-666-6775c1de5.webp 666w" sizes="(max-width: 767px) 100vw, 80vw" width="666" height="500" />
</a>

</div>

<h2 id="version-the-data">Version the data</h2>

<p>If we follow <a href="https://dvc.org/doc/start" target="_blank" rel="noopener noreferrer">DVC get started page</a>, we need to initialize the project running <code>dvc init</code> so let’s run that first and commit those internal files to github.com</p>

<pre><code class="language-bash">git init
dvc init
git commit -m "Initialize DVC"
</code></pre>

<p>Let’s now add our data and annotations to DVC.</p>

<pre><code class="language-bash">dvc add data
</code></pre>

<p>This may take a while since it needs to compute hashes for all files in our data directory. Two files are generated, the <code>.gitignore</code> that will inform git that it must ignore the <code>data</code>/ directory and <code>data.dvc</code>, a small text file in a human-readable format used by dvc to track changes that we can upload to git. Let’s add can add this files and commit the new changes.</p>

<pre><code class="language-bash">git add .gitignore data.dvc 
git commit -m "Added data to dvc"
</code></pre>

<p>Last step will be to configure our Google Drive remote. For this, I created a new folder in my personal gdrive called <code>dvc_data</code> so you should do the same in your own gdrive. After that I will add that folder as a dvc remote and I will need to grant DVC the necessary permissions to access my gdrive account. This can be easily done after running <code>dvc push</code> following the link that promts when running the command. Have in mind that the push step may take a while to complete depending on your internet connection.</p>

<pre><code class="language-bash">dvc remote add -d gdrive-remote gdrive://root/dvc_data
git commit .dvc/config -m "Configure local remote" # Commit changes to git
dvc push # Upload data to gdrive
</code></pre>

<p>We are now tracking our images and annotations with DVC and have pushed it to our google drive remote storage.</p>

<h2 id="split-the-data">Split the data</h2>

<p>We have a file <code>train_sample.json</code> that contains all our annotations. We need to split this file in training and validation subsets so we can properly train our model in a near future. We are going to use pyodi’s <a href="https://gradiant.github.io/pyodi/reference/apps/coco-split/" target="_blank" rel="noopener noreferrer">coco random-split</a> app for this task, since it is very easy to execute.
Let’s reserve a 20% of the total data for validation:</p>

<pre><code class="language-bash">pyodi coco random-split data/coco_sample/annotations/train_sample.json data/coco_sample/annotations/split --val-percentage 0.2
</code></pre>

<p>This creates two new files <code>split_train.json</code>and <code>split_val.json</code>. Let’s add them to dvc, that will magically recognize that we have only added two new files, and commit changes to git:</p>

<pre><code class="language-bash">dvc add data/
git commit data.dvc -m "Add dataset splits"
dvc push
</code></pre>

<h2 id="tag-our-data-with-versions">Tag our data with versions</h2>

<p>You must bear in mind that if we now move through our git history, we can also retrieve the state of our data in that commit or specific moment thanks to DVC. Anyway, I always like to tag the versions of my dataset so that I can easily understand what the state was at all times. Let’s do this now and tag the initial version of our dataset and push our changes to github.</p>

<pre><code class="language-bash">git tag -a "v1.0" -m "Initial version, fast.ai COCO subset. 0.2 validation split"
git push --tags
</code></pre>

<p>Let’s imagine that for any reason we need to create a new version of our dataset saving only ten percent of our data as validation. We could simply run pyodi, override our actual annotations and push the new changes without fear to loose any data. Let’s try that:</p>

<pre><code class="language-bash">pyodi coco random-split data/coco_sample/annotations/train_sample.json data/coco_sample/annotations/split --val-percentage 0.1
dvc add data/
git commit data.dvc -m "New split with 0.1 validation"
dvc push
git tag -a "v2.0" -m "0.2 Validation split"
git push --tags
</code></pre>

<p>That’s it we now have two version of our dataset. If we want to move to our previous version we can simply run:</p>

<pre><code class="language-bash">git checkout v1.0
dvc checkout
</code></pre>

<h2 id="continuous-integration-for-data">Continuous Integration for data</h2>

<p>We have used DVC for track and save data the same way we do with code. So we can also add some test to our data to make sure that we do not commit any error that can harm our training. Since we have used Google Drive as a remote storage for our data, we can configure our CI pipeline to download our data from there and run our tests.</p>

<p>First of all we need to store our gdrive credentials as a Github secret. You can go to you repository settings in Github and create a new secret named <code>GDRIVE_CREDENTIALS_DATA</code>, and paste there the contents of your <code>.dvc/tmp/gdrive-user-credentials.json</code>. This file should have been automatically created after you give DVC permissions to your Google Drive account. You can read more about this in <a href="https://dvc.org/doc/user-guide/setup-google-drive-remote#authorization" target="_blank" rel="noopener noreferrer">DVC documentation</a>.</p>

<p>Let’s create an example test in charge of checking that our annotations follow COCO format guidelines. We can use pydantic for data validation defining how annotation should be using python type annotations. We now for example that categories or our dataset can only take six different values and bounding boxes must be a list of four integers. Pydantic allows us to define this rules in a very efficient an flexible manner.</p>

<p>Create a new file <code>tests/test_annotations.py</code> and paste the following content:</p>

<pre><code class="language-python">import json
from pathlib import Path
import pytest

from typing import get_args, List, Literal
from pydantic import BaseModel, conint, confloat, conlist

CATEGORY_NAMES = Literal["chair", "couch", "tv", "remote", "book", "vase"] 

class COCOCategory(BaseModel):
    id: int
    name: CATEGORY_NAMES


class COCOImage(BaseModel):
    id: int
    file_name: str


class COCOAnnotation(BaseModel):
    image_id: int
    bbox: conlist(int, min_items=4, max_items=4)
    category_id: int


class COCODetectionDataset(BaseModel):
    images: List[COCOImage]
    annotations: List[COCOAnnotation]
    categories: List[COCOCategory]


@pytest.mark.parametrize("split", ["train", "val"])
def test_coco_format(split):

    annotations_file = f"data/coco_sample/annotations/split_{split}.json"
    
    with open(annotations_file, "r") as f:
        dataset = COCODetectionDataset(**json.load(f))

    # Check image ids are unique
    image_ids = [img.id for img in dataset.images]
    image_ids_set = set(image_ids)
    assert len(image_ids) == len(image_ids_set)

    # Check annotation ids are unique
    categories = [cat.id for cat in dataset.categories]
    categories_set = set(categories)
    assert len(categories) == len(categories_set)

    # Check each annotation corresponds with existent image
    for annotation in dataset.annotations:
        assert annotation.image_id in image_ids_set
</code></pre>

<p>Note we added a test that will ensure that:</p>

<ul>
  <li>Loaded data is validated with pydantic</li>
  <li>Image ids are unique</li>
  <li>Category ids are unique</li>
  <li>All annotations are associated with an existent image id</li>
</ul>

<p>We have the test so we need to define a workflow that automatically runs this when we push some changes to our main branch. Create a new file <code>.github/workflows/ci.yaml</code> and paste the following code:</p>

<pre><code class="language-yaml">name: Continuous Integration

on:
  push:
    branches: [main]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - uses: iterative/setup-dvc@v1 

      - name: Get annotations from dvc remote
        run: dvc pull data/coco_sample/annotations 
        env:
          GDRIVE_CREDENTIALS_DATA: $

      - name: Run tests
        run: |
          pip install pytest pydantic
          pytest tests
</code></pre>

<p>This script is very intuitive. First we checkout our repo and setup DVC. After that we pull just the annotation files using using the command <code>dvc pull data/coco_sample/annotations</code>. Think that if we run <code>dvc pull</code> without extra argument we would have to wait before all images are downloaded and we do not need them for this type of test.</p>

<p>If we add, commit and push all this changes to Github we can see how our workflow triggers and runs the associated job:</p>

<pre><code class="language-bash">git add .github tests
git commit -m "Add tests"
git push
</code></pre>

<div class="post-center-image">
<a href="/assets/images/fullsize/posts/2021-07-01-dvc-tutorial/ci.jpg">
  <img loading="lazy" src="/generated/assets/images/fullsize/posts/2021-07-01-dvc-tutorial/ci-800-4fd35c01c.jpg" alt="Github CI results caption" srcset="/generated/assets/images/fullsize/posts/2021-07-01-dvc-tutorial/ci-400-58e8b520e.webp 400w, /generated/assets/images/fullsize/posts/2021-07-01-dvc-tutorial/ci-800-58e8b520e.webp 800w, /generated/assets/images/fullsize/posts/2021-07-01-dvc-tutorial/ci-917-58e8b520e.webp 917w" sizes="(max-width: 767px) 100vw, 80vw" width="917" height="472" />
</a>

</div>

<p>That’s it! Our test completed successfully!</p>

<h2 id="conclusion">Conclusion</h2>

<p>DVC help us to keep version of our data and models. In this short post we have learnt a few things:</p>

<ul>
  <li>
    <p>We have learned how to setup DVC and add a Google Drive remote</p>
  </li>
  <li>
    <p>We have pushed our data to the DVC remote and tagged different versions of it</p>
  </li>
  <li>
    <p>We have added some simple tests for our data and how to set up a CI worflow that runs on Github servers.</p>
  </li>
</ul>

<p><em>Any ideas for future posts or is there something you would like to comment? Please feel free to reach out via <a href="https://twitter.com/mmeendez8" target="_blank" rel="noopener noreferrer">Twitter</a> or <a href="https://github.com/mmeendez8" target="_blank" rel="noopener noreferrer">Github</a></em></p>

  
</div>

<div class="comments">
  <script src="https://utteranc.es/client.js"
        repo="mmeendez8/mmeendez8.github.io"
        issue-term="url"
        theme="github-light"
        crossorigin="anonymous"
        async>
  </script>
</div>

    <div class="footer">
      <div class="footer-sign">
      <p> <a  href=/index.html#top>Miguel Mendez </a></p>
      </div>

      <div class="footer-thanks">
        <p>based on <a href="http://web.media.mit.edu/~msaveski" target="_blank" rel="noopener">Martin Saveski</a> and <a href='https://marinaaisa.com/' target="_blank" rel="noopener">Marina Aisa</a> templates</p>
      </div>

      <div class="footer-icons">
        <a href='https://github.com/mmeendez8' target="_blank" rel="noopener">
          <i class="icon-github-circled" aria-hidden="true"></i>
        </a>

        <a href='https://www.linkedin.com/in/miguel-mendez/' target="_blank" rel="noopener">
          <i class="icon-linkedin-squared" aria-hidden="true"></i>
        </a>

        <a href='https://twitter.com/mmeendez8' target="_blank" rel="noopener">
          <i class="icon-twitter-squared" aria-hidden="true"></i>
        </a>

        <a href='/feed.xml' target="_blank" rel="noopener">
          <i class="icon-rss-squared" aria-hidden="true"></i>
        </a>
        
      </div>

    </div>

  <!-- End Document
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <script type="text/javascript" src=/libs/external/lightbox/lightbox.js defer></script>
  
  <!-- Mathjax -->
  

  <!-- Highlight.js -->
  <script>
    document.addEventListener('DOMContentLoaded', (event) => {
        hljs.highlightAll();
    });
</script>

</body>

</html>
