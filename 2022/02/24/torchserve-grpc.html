<!DOCTYPE html>
<html lang="en" id="top">

<head>

  <!-- Basic Page Needs
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->

  <meta charset="utf-8">
  <title>Miguel Méndez | Torchserve in Computer Vision: REST vs gRPC</title>
  <meta name="author" content="Miguel Mendez">
  <meta property="og:website" content="Miguel Mendez personal website">
  
  
  <meta name="description" property="og:description" content="This post compares the performance of gRPC and REST communication protocols for serving a computer vision deep learning model using TorchServe. I tested both protocols and looked at the pros and cons of each. The goal is to help practitioners make informed decisions when choosing the right communication protocol for their use case.">
  

  
  <meta name="image" property="og:image" content="https://mmeendez8.github.io/assets/images/fullsize/posts/2022-02-24-torchserve-grpc/thumbnail.jpg">
  

  <!-- Mobile Specific Metas
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <!-- CSS
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <link rel="stylesheet" href=/libs/custom/my_css.css>
  <link rel="stylesheet" href=/libs/external/fonts/fonts.css>

  <link rel="preload" href=/libs/custom/syntax.css as="style" onload="this.onload=null;this.rel='stylesheet'">
  <noscript><link rel="stylesheet" href=/libs/custom/syntax.css></noscript>

  <!-- Fontello
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <link rel="stylesheet"
    href=/libs/external/fontello-33e07bd3/css/fa_icons_fontello.css>

  <!-- Favicon
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <link rel="icon" type="image/png" href=/libs/icon.png>
  <link rel="shortcut icon" type="image/png" href=/libs/icon.png>

  <!-- Google Analytics -->
  <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-LMHYVFNF1J"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-LMHYVFNF1J');
</script>
    <!-- Twitter cards -->
  <meta name="twitter:site" content="@https://twitter.com/mmeendez8">
  <meta name="twitter:title" content="Torchserve in Computer Vision: REST vs gRPC">
  
  
  <meta name="twitter:description" content="This post compares the performance of gRPC and REST communication protocols for serving a computer vision deep learning model using TorchServe. I tested both protocols and looked at the pros and cons of each. The goal is to help practitioners make informed decisions when choosing the right communication protocol for their use case.">
  
  

  
  <meta name="twitter:card"  content="summary_large_image">
  <meta name="twitter:image" content="https://mmeendez8.github.io/assets/images/fullsize/posts/2022-02-24-torchserve-grpc/thumbnail.jpg">
  

  <!-- end of Twitter cards -->
  

  <!-- Mathjax -->
  
    <script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/MathJax.js?config=TeX-MML-AM_CHTML">
  MathJax.Hub.Config({
      tex2jax: {
          inlineMath: [["$", "$"], ["\\(", "\\)"]],
          processEscapes: true
      }
  });
</script>
  
</head>

<body>

  <header class="the-post-header">
    <div class="container">
      <a href="/">
        <h3>Miguel Méndez</h3>
      </a>
      <div>
        <a  href=/index.html#posts>
         <h3 class="posts-link">Posts</h3>
        </a>
      </div>
    </div>
</header>

<div class="the-post-title-placeholder">
  <div class="offset">
    <div class="the-post-title-text">
      <span class="the-post-date">February 24, 2022 </span>
      <h1 class="the-post-title">Torchserve in Computer Vision: REST vs gRPC</h1>
      <p>Benchmarking protocols performance for sending images</p>
    </div>
  </div>

  <div class="the-post-title-image">
    <img src="/generated/assets/images/fullsize/posts/2022-02-24-torchserve-grpc/thumbnail-800-0a3487f5b.jpg" alt="Torchserve in Computer Vision: REST vs gRPC" srcset="/generated/assets/images/fullsize/posts/2022-02-24-torchserve-grpc/thumbnail-400-0fd0326d8.webp 400w, /generated/assets/images/fullsize/posts/2022-02-24-torchserve-grpc/thumbnail-600-0fd0326d8.webp 600w, /generated/assets/images/fullsize/posts/2022-02-24-torchserve-grpc/thumbnail-800-0fd0326d8.webp 800w, /generated/assets/images/fullsize/posts/2022-02-24-torchserve-grpc/thumbnail-1000-0fd0326d8.webp 1000w" sizes="(max-width: 767px) 100vw, 50vw" width="3200" height="1879">

  </div>
</div>

<div class="container the-post-content">

  <p>Special thanks to <a href="https://www.linkedin.com/in/jguzmanfd/">Javier Guzman</a> for working with me in completing the benchmarking discussed in this blog post.</p>

<p>In the past few weeks, we have been exploring the potential advantages of adopting gRPC to enhance the performance of our services. Although I have conducted extensive research on this topic, I have not been able to find relevant information that specifically addresses our use case, which involves transmitting images to a model server and receiving a response in the most efficient manner. While there are numerous benchmarks that demonstrate significant performance improvements when migrating from REST to gRPC using structured data, it has been challenging to locate a similar benchmark for image transmission… And that is the main reason behind this post!</p>

<p>All the code for the different benchmarks can be found in <a href="https://github.com/mmeendez8/grpc_vs_rest" target="_blank" rel="noopener noreferrer">this Github repository</a>. You can find instructions in the README file. It’s important to note that our primary objective was to conduct this testing on our cloud infrastructure, where both the servers and clients were deployed on the same Kubernetes cluster. This allowed us to replicate a real-world scenario as closely as possible.</p>

<h2 id="some-thoughts-on-grpc">Some thoughts on gRPC</h2>

<p>When you start reading about gRPC, you soon realize that it involves two main things that can really help you to speed up your system communications.</p>

<h3 id="http2">HTTP2</h3>

<p>gRPC is built on the HTTP/2 protocol, which was specifically designed to address the latency issues of its predecessor, HTTP/1.1. There are two key features of HTTP/2 that are particularly relevant to our benchmarking efforts:</p>

<ul>
  <li>
    <p><strong>Multiplexed streams</strong>: With HTTP/2, multiple requests and responses can be transmitted over a single connection. While HTTP/1.1 can also reuse connections through pooling, the ability to multiplex streams becomes more important in scenarios with a large number of servers, where HTTP/1.1 may need to open and maintain a large number of connections.</p>
  </li>
  <li>
    <p><strong>Binary protocol</strong>: Unlike HTTP/1.1, which is text-based, HTTP/2 uses a binary protocol that reduces message size and facilitates more efficient parsing. This can have a significant impact on performance, particularly when dealing with large datasets such as images.</p>
  </li>
</ul>

<h3 id="protobuf">Protobuf</h3>

<p>Protocol Buffers, also known as Protobuf, is a language-agnostic binary serialization format developed by Google. It is used for efficient data <strong>serialization of structured data</strong> and communication between applications. It is faster than JSON for two reasons: messages are shorter and serialization (convert messages to and from bytes) is faster.</p>

<p>In <a href="https://nilsmagnus.github.io/post/proto-json-sizes/" target="_blank" rel="noopener noreferrer">this post</a> you can see a good comparison of Protobuf vs JSON sizes for structured data. TLDR: Protobuf is always smaller than gzipped json but seems to lose its clear advantage when mesage sizes are large.</p>

<h3 id="how-does-this-apply-to-images">How does this apply to images?</h3>

<p>Structured data is text that has been predefined and formatted to a set structure. Protobuf can take advantage of the schema definitions of the data to speed up serialization and compression size. Things are different with images. Basically if you want to convert an image to bytes in an efficient manner and without losing information you have to use specific handcrafted methods that have been carefully designed for this, such as JPEG, PNG… In other words, Protobuf is not going to help you here since compression and serialization will depend on your image library. See this example:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># create random 100x100 rgb image
</span><span class="n">image</span> <span class="o">=</span> <span class="n">numpy</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">rand</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span> <span class="o">*</span> <span class="mi">255</span>
<span class="c1"># serialize image to jpg using opencv
</span><span class="n">encoded_image</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="nf">imencode</span><span class="p">(</span><span class="s">".jpg"</span><span class="p">,</span> <span class="n">image</span><span class="p">)[</span><span class="mi">1</span><span class="p">].</span><span class="nf">tobytes</span><span class="p">()</span>
<span class="c1"># fake send with grpc
</span><span class="n">grpc</span><span class="p">.</span><span class="nf">send</span><span class="p">(</span><span class="n">encoded_image</span><span class="p">)</span>
</code></pre></div></div>

<p>The point here is that Protobuf is not really helping. Given that it is one of key points of gRPC, differences between REST and gRPC cannot be that high here… Let’s check this with real numbers :)</p>

<h2 id="1-base-benchmark">1. Base benchmark</h2>

<p>First thing we wanted to do is to check if we were able to reproduce those benchmarks we found on the web. The idea is simple, create two equivalent REST and gRPC servers and measure the time they take to process and respond to different requests.
The gRPC server has been implemented using <a href="https://grpc.io/docs/languages/python/basics/" target="_blank" rel="noopener noreferrer">python grpc library</a> and we have used <a href="https://fastapi.tiangolo.com/" target="_blank" rel="noopener noreferrer">FastAPI</a> for the REST one.</p>

<div class="post-center-image">
<img loading="lazy" src="/generated/assets/images/fullsize/posts/2022-02-24-torchserve-grpc/cat_bytes-768-253323f5f.png" alt="Cat being compressed to bytes" srcset="/generated/assets/images/fullsize/posts/2022-02-24-torchserve-grpc/cat_bytes-400-b0be83dae.webp 400w, /generated/assets/images/fullsize/posts/2022-02-24-torchserve-grpc/cat_bytes-600-b0be83dae.webp 600w, /generated/assets/images/fullsize/posts/2022-02-24-torchserve-grpc/cat_bytes-768-b0be83dae.webp 768w" sizes="(max-width: 767px) 100vw, 80vw" width="768" height="768" />

</div>

<p class="image-caption"><em>This is what Stable Diffusion creates with the prompt “an image of a cat is being encoded into a chunk of bytes”</em></p>

<p>We decided to measure three different requests and using a single response for all of them. The gRPC <code class="language-plaintext highlighter-rouge">.proto</code> file for those requests looks like the following:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">BasicRequest</span><span class="p">(</span><span class="n">BaseModel</span><span class="p">):</span>
    <span class="s">"""
    Structured data request, we expect to match online benchmarks with this
    """</span>
    <span class="n">field1</span><span class="p">:</span> <span class="nb">str</span>
    <span class="n">field2</span><span class="p">:</span> <span class="nb">str</span>
    <span class="n">field3</span><span class="p">:</span> <span class="nb">int</span>
    <span class="n">field4</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span>

<span class="k">class</span> <span class="nc">ImageBase64Request</span><span class="p">(</span><span class="n">BaseModel</span><span class="p">):</span>
    <span class="s">"""
    Encode image as a string using Base64 encoding. 
    This is simple and very bad solution (but simple to do) that should be always avoided
    """</span>
    <span class="n">image</span><span class="p">:</span> <span class="nb">str</span>

<span class="k">class</span> <span class="nc">ImageBinaryRequest</span><span class="p">(</span><span class="n">BaseModel</span><span class="p">):</span>
    <span class="s">"""
    Contains an image encoded as bytes.
    """</span>
    <span class="n">image</span><span class="p">:</span> <span class="nb">bytes</span>

<span class="k">class</span> <span class="nc">BasicResponse</span><span class="p">(</span><span class="n">BaseModel</span><span class="p">):</span>
    <span class="n">prediction1</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span>
    <span class="n">prediction2</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span>
</code></pre></div></div>

<p>Note REST’s requests and responses are identical to these so we can make a fair comparison.</p>

<p>Our client does a very simple thing, it sends concurrent requests to each server and waits for a response. It then computes the average time it took. Pseudocode for the client it is shown below:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">times</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
    <span class="n">start</span><span class="o">=</span> <span class="nf">time</span><span class="p">()</span>
    <span class="nf">send_concurrent_request_to_specific_server</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
    <span class="n">times</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="nf">time</span><span class="p">()</span> <span class="o">-</span> <span class="nf">start</span><span class="p">())</span>

<span class="n">average_time</span> <span class="o">=</span> <span class="nf">mean</span><span class="p">(</span><span class="n">times</span><span class="p">)</span>
</code></pre></div></div>

<p>We tested this for three different image sizes. Results are collected below:</p>

<div class="table-wrapper">

  <table>
    <thead>
      <tr>
        <th> </th>
        <th>Basic (0.001 MB)</th>
        <th>B64 (0.306 MB)</th>
        <th>Binary (0.229 MB)</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td>REST</td>
        <td>0.0723</td>
        <td>0.0943</td>
        <td>0.0572</td>
      </tr>
      <tr>
        <td>gRPC</td>
        <td>0.0093 (x7.7)</td>
        <td>0.0179 (x5.2)</td>
        <td>0.0120 (x4.7)</td>
      </tr>
    </tbody>
  </table>

  <p>Table 1. Results for small images: 360x640</p>

</div>

<div class="table-wrapper">

  <table>
    <thead>
      <tr>
        <th> </th>
        <th>Basic (0.001 MB)</th>
        <th>B64 (1.160 MB)</th>
        <th>Binary (0.870 MB)</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td>REST</td>
        <td>0.0611</td>
        <td>0.2350</td>
        <td>0.0872</td>
      </tr>
      <tr>
        <td>gRPC</td>
        <td>0.0090 (x6.7)</td>
        <td>0.0926 (x2.5)</td>
        <td>0.0570 (x1.5)</td>
      </tr>
    </tbody>
  </table>

  <p>Table 2. Results for medium images: 720x1280</p>

</div>

<div class="table-wrapper">

  <table>
    <thead>
      <tr>
        <th> </th>
        <th>Basic (0.001 MB)</th>
        <th>B64 (3.094 MB)</th>
        <th>Binary (2.320 MB)</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td>REST</td>
        <td>0.0583</td>
        <td>0.8056</td>
        <td>0.1909 (x1.03)</td>
      </tr>
      <tr>
        <td>gRPC</td>
        <td>0.0097 (x6)</td>
        <td>0.2793 (x2.9)</td>
        <td>0.1974</td>
      </tr>
    </tbody>
  </table>

  <p>Table 3. Results for large images: 1080x1920</p>

</div>

<p>We can extract some conclussion from previous tables:</p>

<ol>
  <li>gRPC achieves around a x6 improvement with respect to REST for structured data (Basic column). The results <a href="https://medium.com/@EmperorRXF/evaluating-performance-of-rest-vs-grpc-1b8bdf0b22da#:~:text=gRPC%20is%20roughly%207%20times,of%20HTTP%2F2%20by%20gRPC." target="_blank" rel="noopener noreferrer">match online benchmarks</a> and we know this is because we are taking advantage of Protobuf serialization and HTTP2 protocol.</li>
  <li>For Base64 and Binary we observe a relation between image size and gRPC performance. As the image size increase, the difference between REST and gRPC are smaller.</li>
  <li>In the Base64 case, gRPC helps to serialize faster and in a more optimal way the string. We know from <a href="https://nilsmagnus.github.io/post/proto-json-sizes/" target="_blank" rel="noopener noreferrer">this post</a> that Protobuf loses its advantage when message size increases.</li>
  <li>Binary is a special case as we know we are not getting any advantage from using Protobuf for our serialization and message size (this is determined by the image format we chose). On the contrary it is harming our performance. There is still  some encoding going on in Protobuf, since it needs to format our chunk of image bytes inside the Protobuf message format. This little thing might be making REST as good as gRPC for large images!</li>
</ol>

<h2 id="torchserve-benchmark">Torchserve benchmark</h2>

<p>I have been using <a href="https://pytorch.org/serve/">TorchServe</a> for a while now and I am quite happy with it. It provides all the flexibility I need and it is quite simple to set up. Model handlers allow you to customize every detail for your specific model without really worrying about other complex things as batching and queing requests. 
I do not pretend to give an overview of TorchServe or make a comparison of its advantages compared to other inference servers, I will let that for a plausible future post.</p>

<p>The documentation for Torchserve’s <a href="https://pytorch.org/serve/grpc_api.html" target="_blank" rel="noopener noreferrer">gRPC API</a> could be improved, as it currently requires users to download the official repository to generate a Python gRPC client stub from the proto files. However, I have attached these files to the repository, so you can easily run the benchmark without having to worry about this step.</p>

<p>The experiment is very similar to the previous one, sending 20 concurrent request and repeating that 10 times to measure the average time. I am going to use one of the pytorch vision model examples, <a href="https://pytorch.org/hub/pytorch_vision_densenet/" target="_blank" rel="noopener noreferrer">densenet161</a>. The model is not important here since we do not really care about inference results. Let’s see some results:</p>

<div class="table-wrapper">

  <table>
    <thead>
      <tr>
        <th> </th>
        <th>B64 (0.306 MB)</th>
        <th>Binary (0.229)</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td>REST</td>
        <td>0.884</td>
        <td>0.628</td>
      </tr>
      <tr>
        <td>gRPC</td>
        <td>X</td>
        <td>0.645</td>
      </tr>
    </tbody>
  </table>

  <p>Table 4. Results for small images: 360x640</p>

</div>

<div class="table-wrapper">

  <table>
    <thead>
      <tr>
        <th> </th>
        <th>B64 (0.306 MB)</th>
        <th>Binary (0.229)</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td>REST</td>
        <td>1.262</td>
        <td>0.946</td>
      </tr>
      <tr>
        <td>gRPC</td>
        <td>X</td>
        <td>0.927</td>
      </tr>
    </tbody>
  </table>

  <p>Table 5. Results for medium images: 720x1280</p>

</div>

<div class="table-wrapper">

  <table>
    <thead>
      <tr>
        <th> </th>
        <th>B64 (0.306 MB)</th>
        <th>Binary (0.229)</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td>REST</td>
        <td>2.188</td>
        <td>1.384</td>
      </tr>
      <tr>
        <td>gRPC</td>
        <td>X</td>
        <td>1.422</td>
      </tr>
    </tbody>
  </table>

  <p>Table 6. Results for large images: 1080x1920</p>

</div>

<p>Translating the insights gained from benchmarking with the base servers can be challenging. The tables indicate that Base64 encoding should be avoided and that there are no significant performance differences between using gRPC and REST.</p>

<p>Two factors contribute to the similar performance results for gRPC and REST. Firstly, the model’s inference time is considerably longer than the networking time, making it difficult to discern the small gains obtained by changing the transmission protocol. For example, sending 20 large images concurrently in the simple base case (Table 3) took roughly 0.19s, whereas we are now spending approximately 1.4 seconds, highlighting the significant impact of model inference time on the comparison.</p>

<p>Secondly, the Torchserve implementation plays a role in these results. It has been observed that Torchserve’s <code class="language-plaintext highlighter-rouge">.proto</code> definition for <a href="https://github.com/pytorch/serve/blob/master/frontend/server/src/main/resources/proto/inference.proto#L20-L23" target="_blank" rel="noopener noreferrer">prediction response</a> is too generic and it cannot be personalized with your model specifics.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">message</span> <span class="n">PredictionResponse</span> <span class="p">{</span>
    <span class="o">//</span> <span class="n">Response</span> <span class="n">content</span> <span class="k">for</span> <span class="n">prediction</span>
    <span class="nb">bytes</span> <span class="n">prediction</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div></div>

<p>This means that your response will be converted to a chunk of bytes so you would not be getting any advantage of Protobuf serialization (similar to what happens with images). A better or more customizable definition, as the one provided by Tfserving, of the <code class="language-plaintext highlighter-rouge">.proto</code> file could help to boost performance.</p>

<h2 id="conclusion">Conclusion</h2>

<p>If you’re using Torchserve to serve computer vision models, it’s recommended to steer clear of gRPC. Our findings show that there are no performance benefits to using gRPC, and it adds complexity to your code while making debugging more challenging due to its non-human-readable messages. Since REST is more commonly used, most developers are already familiar with it. Switching to gRPC in this scenario comes with a learning curve that doesn’t offer any significant advantages.</p>

<p><em>Any ideas for future posts or is there something you would like to comment? Please feel free to reach out via <a href="https://twitter.com/mmeendez8" target="_blank" rel="noopener noreferrer">Twitter</a> or <a href="https://github.com/mmeendez8" target="_blank" rel="noopener noreferrer">Github</a></em></p>


  
</div>


  <div >

    <div class="footer">
      <div class="footer-sign">
      <p> <a  href=/index.html#top>Miguel Méndez </a></p>
      </div>

      <div class="footer-thanks">
        <p>based on <a href="http://web.media.mit.edu/~msaveski" target="_blank" rel="noopener">Martin Saveski</a> and <a href='https://marinaaisa.com/' target="_blank" rel="noopener">Marina Aisa</a> templates</p>
      </div>

      <div class="footer-icons">
        <a href='https://github.com/mmeendez8' target="_blank" rel="noopener">
          <i class="icon-github-circled" aria-hidden="true"></i>
        </a>

        <a href='https://www.linkedin.com/in/miguel-mendez/' target="_blank" rel="noopener">
          <i class="icon-linkedin-squared" aria-hidden="true"></i>
        </a>

        <a href='https://twitter.com/mmeendez8' target="_blank" rel="noopener">
          <i class="icon-twitter-squared" aria-hidden="true"></i>
        </a>

        <a href='https://medium.com/@miguelmendez_' target="_blank" rel="noopener">
          <i class="icon-medium" aria-hidden="true"></i>
        </a>

        <a href='https://stackoverflow.com/users/8380638/m33n' target="_blank" rel="noopener">
          <i class="icon-stackoverflow" aria-hidden="true"></i>
        </a>
      </div>

    </div>

  <!-- End Document
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
</body>

</html>
